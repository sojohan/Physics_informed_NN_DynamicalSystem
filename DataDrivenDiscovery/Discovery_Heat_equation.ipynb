{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfUzkSR1Txr0",
        "outputId": "92020d3d-b97c-4c77-ae6e-124c6470da88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.39.2-py2.py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.41 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.39.2 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyDOE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW0Is136vDFr",
        "outputId": "2b3b3365-ea65-4230-8ffc-a6965079e4f7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyDOE in /usr/local/lib/python3.10/dist-packages (0.3.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyDOE) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyDOE) (1.11.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndoVsjLJixL6",
        "outputId": "c09f7d63-f890-4caf-cf17-81a4efab69eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from argparse import ArgumentParser\n",
        "from collections import defaultdict\n",
        "from math import ceil, sin\n",
        "from math import floor\n",
        "\n",
        "#from jax.example_libraries import optimizers\n",
        "#from jax.experimental.ode import odeint\n",
        "\n",
        "import scipy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "#import torch_xla\n",
        "#import torch_xla.core.xla_model as xm\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad\n",
        "from torch.autograd.functional import jacobian\n",
        "from torch.nn.modules.container import T\n",
        "\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.integrate import solve_ivp\n",
        "import matplotlib as mpl\n",
        "from functools import partial"
      ],
      "metadata": {
        "id": "BoZ4G6nNTm-D"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyDOE import lhs"
      ],
      "metadata": {
        "id": "YL1INlGovBZ5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this notebook with cuda"
      ],
      "metadata": {
        "id": "-BFfiNTaX4UE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "5JtyrI-TTzVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "id": "ITH_8vUaT3S_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2e41ba84-7ba0-48b9-9c7c-f5a33bf9a3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mSObD_4dX2v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device=xm.xla_device()"
      ],
      "metadata": {
        "id": "gYR3HnJs9FmP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmnRRWpJaSia",
        "outputId": "b4140b50-81a2-4d85-caa8-4939d3c8df84"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = torch.tensor(0.01)  # Example value for thermal diffusivity\n",
        "hidden_dim =40\n",
        "hidden_layers = 6\n",
        "input_dim=2\n",
        "output_dim=1\n",
        "lambda_f=1\n",
        "resblocks=0 # 0 when not Resnet\n",
        "activation='gelu'\n",
        "learningRate=0.0001\n",
        "wd=1e-4\n",
        "N=3000\n",
        "N_f=3000\n",
        "N_u=1000\n",
        "n_epochs=6000\n",
        "network='MLP' # MLP Or Resnet"
      ],
      "metadata": {
        "id": "R9458N0WzsDl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    # set the wandb project where this run will be logged\n",
        "    project=\"Heatfinal\",\n",
        "\n",
        "    # track hyperparameters and run metadata\n",
        "    config={\n",
        "    \"Thermal_diff\": alpha,\n",
        "    \"N_f\": N_f,\n",
        "    \"N_u\":N_u,\n",
        "    \"learning_rate\": learningRate,\n",
        "    \"weight_decay\": wd,\n",
        "    \"hidden_layers\": hidden_layers,\n",
        "    \"hidden_dim\": hidden_dim,\n",
        "    'input_dim': input_dim,\n",
        "    'output_dim': output_dim,\n",
        "    'activation':activation,\n",
        "    'lambdaB': lambda_f,\n",
        "    'numResblocks': resblocks,\n",
        "    \"epochs\": n_epochs,\n",
        "    'network': network\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "WjJE4qrEYGjS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "14c367e6-a018-457b-8cd8-adef4c92180f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240111_162258-z0tihha1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sojohan/Heatfinal/runs/z0tihha1' target=\"_blank\">laced-deluge-84</a></strong> to <a href='https://wandb.ai/sojohan/Heatfinal' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sojohan/Heatfinal' target=\"_blank\">https://wandb.ai/sojohan/Heatfinal</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sojohan/Heatfinal/runs/z0tihha1' target=\"_blank\">https://wandb.ai/sojohan/Heatfinal/runs/z0tihha1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sojohan/Heatfinal/runs/z0tihha1?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7c1fea0dc580>"
            ]
          },
          "metadata": {},
          "execution_count": 709
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot the the three loss terms initial/boundary condition and residual\n",
        "def plot_loss(losses):\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.canvas.manager.set_window_title(\"Loss terms\")\n",
        "\n",
        "    # Extract the loss values from the dictionary\n",
        "    lossNN = losses[\"Res\"]\n",
        "    lossEQ = losses[\"BC\"]\n",
        "    lossIC=losses['IC']\n",
        "    lossData=losses['Data']\n",
        "    # Plot both losses\n",
        "    ax.plot(lossNN, label='Residual')\n",
        "    ax.plot(lossEQ, label='BC')\n",
        "    ax.plot(lossIC, label='IC')\n",
        "    #ax.plot(lossData, label='Data')\n",
        "\n",
        "    ax.legend()\n",
        "    ax.set_xlabel(\"Epoch\")\n",
        "    ax.set_ylabel(\"Loss\")\n",
        "    ax.set_title(\"Neural Network and Equation/BC/IC Losses over Epochs\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "MJ4H4cht4HE_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = defaultdict(list)"
      ],
      "metadata": {
        "id": "mMRzIcZF2aM8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Xavier initialization\n",
        "def xavier_init(module):\n",
        "        for m in module.modules():\n",
        "            if type(m) == nn.Linear:\n",
        "                nn.init.xavier_uniform_(m.weight)\n"
      ],
      "metadata": {
        "id": "7uIjfCsAzzUB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sinusoidal activation function\n",
        "class SinusActivation(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sin(x)"
      ],
      "metadata": {
        "id": "bF03o766z5RR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP neural network as a function of neurons (hidden_dim), number of layers and activation function\n",
        "def construct_network(input_dim, output_dim, hidden_dim, hidden_layers, activation):\n",
        "    # Activation function mapping\n",
        "    activations = {\n",
        "        'swish': nn.SiLU,\n",
        "        'tanh': nn.Tanh,\n",
        "        'relu': nn.ReLU,\n",
        "        'gelu': nn.GELU,\n",
        "        'softplus': nn.Softplus,\n",
        "        'sin': SinusActivation\n",
        "    }\n",
        "\n",
        "    # Check if activation is valid\n",
        "    if activation not in activations:\n",
        "        raise ValueError(f\"Invalid activation function. Expected one of: {list(activations.keys())}\")\n",
        "\n",
        "    ActivationFunc = activations[activation]\n",
        "\n",
        "    # Construct the layers\n",
        "    layers = [nn.Linear(input_dim, hidden_dim), ActivationFunc()]\n",
        "    for _ in range(hidden_layers):\n",
        "        layers.extend([nn.Linear(hidden_dim, hidden_dim), ActivationFunc()])\n",
        "    layers.append(nn.Linear(hidden_dim, output_dim))\n",
        "    layers.append(ActivationFunc())  # Activation function for the output layer\n",
        "\n",
        "\n",
        "    # Create the network\n",
        "    net = nn.Sequential(*layers).double().to(device)\n",
        "\n",
        "    xavier_init(net)\n",
        "    return net\n",
        "\n",
        "# Example usage:\n",
        "# net = construct_network(10, 2, 128, 3, 'relu', device='cuda')\n",
        "\n"
      ],
      "metadata": {
        "id": "trSChYnBz-RU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extend the MLP network with a learnable parameter\n",
        "class PINN(nn.Module):\n",
        "    def __init__(self, base_network):\n",
        "        super(PINN, self).__init__()\n",
        "        self.network = base_network\n",
        "        self.nu = nn.Parameter(torch.tensor([-5.0], dtype=torch.float64))  # Initialize nu as a learnable parameter\n",
        "        #self.phi=nn.Parameter(torch.tensor([0.5], dtype=torch.float64))\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ],
      "metadata": {
        "id": "rFP-q5RGYvLD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet neural network as a function of neurons, number resnet block, the size of last layer and the activation function\n",
        "class ResidualBlockScalar(nn.Module):\n",
        "    def __init__(self, features, activation_func):\n",
        "        super(ResidualBlockScalar, self).__init__()\n",
        "        self.linear1 = nn.Linear(features, features)\n",
        "        self.linear2 = nn.Linear(features, features)\n",
        "        self.activation = activation_func()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = self.activation(self.linear1(x))\n",
        "        x = self.linear2(x)\n",
        "        return self.activation(x + residual)\n",
        "\n",
        "class SimpleResNetScalar(nn.Module):\n",
        "    def __init__(self, num_classes, features, num_blocks, activation='relu'):\n",
        "        super(SimpleResNetScalar, self).__init__()\n",
        "        activations = {\n",
        "            'swish': nn.SiLU,\n",
        "            'tanh': nn.Tanh,\n",
        "            'relu': nn.ReLU,\n",
        "            'gelu': nn.GELU,\n",
        "            'softplus': nn.Softplus,\n",
        "            'sin': SinusActivation  # Assuming SinusActivation is defined elsewhere\n",
        "        }\n",
        "\n",
        "        self.linear1 = nn.Linear(2, features)\n",
        "        self.activation = activations[activation]()\n",
        "        self.res_blocks = nn.ModuleList([ResidualBlockScalar(features, activations[activation]) for _ in range(num_blocks)])\n",
        "        self.linear2 = nn.Linear(features, num_classes)\n",
        "        self.final_activation = activations[activation]()  # Activation function after the final layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.linear1(x))\n",
        "        for block in self.res_blocks:\n",
        "            x = block(x)\n",
        "        x = self.linear2(x)\n",
        "        return self.final_activation(x)  # Apply activation function here\n",
        "\n",
        "# Example instantiation\n",
        "# model = SimpleResNetScalar(num_classes=output_dim, features=hidden_dim, num_blocks=resblocks, activation='swish')\n"
      ],
      "metadata": {
        "id": "FzK6oWYv2ArJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A2__k3lg0zg",
        "outputId": "e931d685-0583-4c64-a6a3-125cf8d17b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleResNetScalar(\n",
            "  (linear1): Linear(in_features=2, out_features=50, bias=True)\n",
            "  (activation): SiLU()\n",
            "  (res_blocks): ModuleList()\n",
            "  (linear2): Linear(in_features=50, out_features=1, bias=True)\n",
            "  (final_activation): SiLU()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from torchinfo import summary"
      ],
      "metadata": {
        "id": "2Ivb6Sx4iS9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#summary(model)"
      ],
      "metadata": {
        "id": "JUqRfrwri6mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Model parameters\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(54)\n",
        "# Interior conditions\n",
        "x_int=lhs(2,N_f)\n",
        "x_int=torch.tensor(x_int)\n",
        "u_int = torch.zeros(N_f, 1)\n",
        "u_train=torch.exp(-alpha * np.pi**2 * x_int[...,0]) * torch.sin(np.pi * x_int[...,1])\n",
        "\n",
        "# Initial conditions\n",
        "x_ini = torch.rand(N_u, 2)\n",
        "x_ini[..., 0] = 0  # t = 0\n",
        "u_ini = torch.sin(np.pi * x_ini[..., 1]).reshape(N_u, 1)\n",
        "\n",
        "# Boundary conditions\n",
        "x_bc = torch.rand(N_u, 2)  # t, 0 to 1\n",
        "x_bc[..., 1] = torch.tensor([0, 1])[torch.randint(0, 2, (N_u,))]  # 0 or 1\n",
        "u_bc = torch.zeros(N_u, 1)\n",
        "\n",
        "# Merge inputs\n",
        "x_inp = torch.cat([x_int, x_bc, x_ini], dim=0).float()\n",
        "u_inp = torch.cat([u_int, u_bc, u_ini], dim=0).float()\n",
        "\n",
        "# Print shapes to verify\n",
        "print(f\"x_inp shape: {x_inp.shape}, u_inp shape: {u_inp.shape}\")\n",
        "x_bc_inp = x_bc\n",
        "x_ini_inp = x_ini\n",
        "#x_inp = x_int\n",
        "u_bc_inp = u_bc\n",
        "u_ini_inp = u_ini\n",
        "#u_inp = u_int\n",
        "\n",
        "x_inp = torch.reshape(x_inp,(-1,2));\n",
        "u_inp = torch.reshape(u_inp,(-1,1));\n",
        "\n",
        "x_bc_inp = torch.reshape(x_bc_inp,(-1,2));\n",
        "u_bc_inp = torch.reshape(u_bc_inp,(-1,1));\n",
        "\n",
        "x_ini_inp = torch.reshape(x_ini_inp,(-1,2));\n",
        "u_ini_inp = torch.reshape(u_ini_inp,(-1,1));\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78Ti_uaQXzDQ",
        "outputId": "655122ba-75c3-46d1-e531-aae1a09fef80"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_inp shape: torch.Size([5000, 2]), u_inp shape: torch.Size([5000, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "#model = PINN()\n",
        "\n",
        "base_network = construct_network(input_dim, output_dim, hidden_dim, hidden_layers, activation)\n",
        "model = PINN(base_network).double().to(device)\n",
        "\n",
        "\n",
        "#model=construct_network(input_dim, output_dim, hidden_dim, hidden_layers, activation)\n",
        "#model = SimpleResNetScalar(num_classes=output_dim, features=hidden_dim, num_blocks=resblocks, activation=activation).double().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learningRate, weight_decay=wd)\n"
      ],
      "metadata": {
        "id": "NSTuo57zVtB-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNmtOlX7_ncy",
        "outputId": "114012c1-6ad5-492c-948b-d30e0d8a82cb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PINN(\n",
            "  (network): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=40, bias=True)\n",
            "    (1): GELU(approximate='none')\n",
            "    (2): Linear(in_features=40, out_features=40, bias=True)\n",
            "    (3): GELU(approximate='none')\n",
            "    (4): Linear(in_features=40, out_features=40, bias=True)\n",
            "    (5): GELU(approximate='none')\n",
            "    (6): Linear(in_features=40, out_features=40, bias=True)\n",
            "    (7): GELU(approximate='none')\n",
            "    (8): Linear(in_features=40, out_features=40, bias=True)\n",
            "    (9): GELU(approximate='none')\n",
            "    (10): Linear(in_features=40, out_features=40, bias=True)\n",
            "    (11): GELU(approximate='none')\n",
            "    (12): Linear(in_features=40, out_features=40, bias=True)\n",
            "    (13): GELU(approximate='none')\n",
            "    (14): Linear(in_features=40, out_features=1, bias=True)\n",
            "    (15): GELU(approximate='none')\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_loss(xint,u_obs):\n",
        "  u_pred=model(xint.double().to(device))\n",
        "  #print(u_obs.shape)\n",
        "  return torch.mean((u_pred.flatten()-u_obs.double().to(device).flatten())**2)"
      ],
      "metadata": {
        "id": "eZASjFOGf8Di"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initial_loss(xinit,uinit):\n",
        "  # Predictions for initial\n",
        "  u_ini_pred = model(xinit.double().to(device))\n",
        "  # return initial loss\n",
        "  return torch.mean((u_ini_pred.flatten() - uinit.double().to(device).flatten()) ** 2)"
      ],
      "metadata": {
        "id": "tFwZJ6KIHQuR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def boundary_loss(xbc,ubc):\n",
        "  # Predictions for boundary conditions\n",
        "  u_bc_pred = model(xbc.double().to(device))\n",
        "  # return loss for boundary conditions\n",
        "  return torch.mean((u_bc_pred.flatten() - ubc.double().to(device).flatten()) ** 2)"
      ],
      "metadata": {
        "id": "NwqqBTWZHSk_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Heat(x_data):\n",
        "  # Calculate prediction of u dependent on x, t\n",
        "  x_physics = x_data.requires_grad_(True)\n",
        "  u = model(x_physics.double().to(device))\n",
        "  # Calculate the grad of u with respect to x\n",
        "  grad_u = torch.autograd.grad(u, x_physics, grad_outputs=torch.ones_like(u)\n",
        "                               , create_graph=True)[0]\n",
        "  u_t = grad_u[:, 0] # The first derivative of u with respect to t\n",
        "  u_x = grad_u[:, 1] # The first derivative of u with respect to x\n",
        "  # Compute the second derivative of u with respect to x\n",
        "  u_xx = torch.autograd.grad(u_x, x_physics, grad_outputs=torch.ones_like(u_x)\n",
        "  , create_graph=True)[0][:, 1]\n",
        "  #alpha_tensor = torch.tensor(alpha)\n",
        "  pde_residual = u_t - torch.exp(model.nu).to(device)*u_xx\n",
        "  return torch.mean(pde_residual**2)\n"
      ],
      "metadata": {
        "id": "c6VBIafHfIf_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_history = []\n",
        "losses={}\n",
        "losses[\"Res\"] = []\n",
        "losses[\"BC\"] = []\n",
        "losses['IC']=[]\n",
        "losses['Data']=[]\n",
        "\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(n_epochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Loss initial condition\n",
        "    #loss_initial = initial_loss(x_ini_inp, u_ini_inp)\n",
        "    # loss boundary condition\n",
        "    #loss_boundary = boundary_loss(x_bc_inp, u_bc_inp)\n",
        "\n",
        "    # Loss physics equation\n",
        "    loss_physics = Heat(x_int.to(device))\n",
        "    loss_data=data_loss(x_int,u_train)\n",
        "    # Total loss\n",
        "    total_loss = lambda_f*(loss_physics)+loss_data\n",
        "    #+loss_initial + loss_boundary\n",
        "    #+loss_data\n",
        "    loss_history.append(total_loss.item())\n",
        "    # Backwadation\n",
        "    total_loss.backward()\n",
        "    # Optimize\n",
        "    optimizer.step()\n",
        "    losses['Res'].append(loss_physics.item())\n",
        "    #losses['BC'].append(loss_boundary.item())\n",
        "    #losses['IC'].append(loss_initial.item())\n",
        "    #losses['Data'].append(loss_data.item())\n",
        "    #wandb.log({\"lossRES\": loss_physics,\n",
        "    #                   \"lossInitial \": loss_initial,\n",
        "    #                   \"LossBoundary\": loss_boundary,\n",
        "    #                    \"LossTotal\": total_loss})\n",
        "    if epoch % 100 == 0:\n",
        "       print(f'Epoch {epoch}, Loss: {total_loss.item()}, Nu:{model.nu.item()} ')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpmg9_6_uyy5",
        "outputId": "ff21a290-dc06-46ed-e45e-f97c06badf60"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.3579532021081022, Nu:-4.9999000019999675 \n",
            "Epoch 100, Loss: 0.1581674847539321, Nu:-4.989904186937837 \n",
            "Epoch 200, Loss: 0.0869268381722262, Nu:-4.979950856667573 \n",
            "Epoch 300, Loss: 0.08667941452204364, Nu:-4.969980571298314 \n",
            "Epoch 400, Loss: 0.08646202861920181, Nu:-4.960005842525172 \n",
            "Epoch 500, Loss: 0.08625156372179932, Nu:-4.950031840330664 \n",
            "Epoch 600, Loss: 0.08603011177549177, Nu:-4.940059082577258 \n",
            "Epoch 700, Loss: 0.08577327301808169, Nu:-4.930086573645976 \n",
            "Epoch 800, Loss: 0.08544209560824034, Nu:-4.9201115367999355 \n",
            "Epoch 900, Loss: 0.08496133258601539, Nu:-4.910128151835809 \n",
            "Epoch 1000, Loss: 0.08415686329063472, Nu:-4.9001238250514785 \n",
            "Epoch 1100, Loss: 0.08253573497970404, Nu:-4.890067672450586 \n",
            "Epoch 1200, Loss: 0.07822441598637854, Nu:-4.8798698132904335 \n",
            "Epoch 1300, Loss: 0.06021178325427562, Nu:-4.869273398063747 \n",
            "Epoch 1400, Loss: 0.004921595815446752, Nu:-4.874030165651614 \n",
            "Epoch 1500, Loss: 0.0014277781920840386, Nu:-4.896553089460102 \n",
            "Epoch 1600, Loss: 0.001041601788835677, Nu:-4.896312213739285 \n",
            "Epoch 1700, Loss: 0.0008731332702316503, Nu:-4.891317744096766 \n",
            "Epoch 1800, Loss: 0.0007474885967756657, Nu:-4.885600298059516 \n",
            "Epoch 1900, Loss: 0.000646722224067178, Nu:-4.879630847139865 \n",
            "Epoch 2000, Loss: 0.0005652277079352081, Nu:-4.873514387668083 \n",
            "Epoch 2100, Loss: 0.0004972624228843906, Nu:-4.86730713850857 \n",
            "Epoch 2200, Loss: 0.00044033010081627054, Nu:-4.86106097943891 \n",
            "Epoch 2300, Loss: 0.00039340209273176384, Nu:-4.854814658750091 \n",
            "Epoch 2400, Loss: 0.00035656134385083125, Nu:-4.848601541159994 \n",
            "Epoch 2500, Loss: 0.00032762491616670207, Nu:-4.842439309144127 \n",
            "Epoch 2600, Loss: 0.00030503736756620737, Nu:-4.836350228553687 \n",
            "Epoch 2700, Loss: 0.00028784951094557444, Nu:-4.830350855022958 \n",
            "Epoch 2800, Loss: 0.0002755259545803458, Nu:-4.824452957480344 \n",
            "Epoch 2900, Loss: 0.0002667519030127143, Nu:-4.818646292830322 \n",
            "Epoch 3000, Loss: 0.00026051780919465593, Nu:-4.8129266743866514 \n",
            "Epoch 3100, Loss: 0.0002562482753468541, Nu:-4.807288000310531 \n",
            "Epoch 3200, Loss: 0.0002535415677298331, Nu:-4.801723320664043 \n",
            "Epoch 3300, Loss: 0.00025191618369171584, Nu:-4.796207860033375 \n",
            "Epoch 3400, Loss: 0.0002510074588445004, Nu:-4.790729258425459 \n",
            "Epoch 3500, Loss: 0.00029045798160554044, Nu:-4.7852743292165 \n",
            "Epoch 3600, Loss: 0.00025062784234565797, Nu:-4.7798399616531455 \n",
            "Epoch 3700, Loss: 0.00025092573385563494, Nu:-4.774402099302129 \n",
            "Epoch 3800, Loss: 0.0002514194069961768, Nu:-4.768956215442277 \n",
            "Epoch 3900, Loss: 0.00025204325035810043, Nu:-4.763500606935196 \n",
            "Epoch 4000, Loss: 0.00025281460930726455, Nu:-4.758031526580749 \n",
            "Epoch 4100, Loss: 0.00025369182031722464, Nu:-4.752541622461394 \n",
            "Epoch 4200, Loss: 0.00025465477433083073, Nu:-4.747031657015228 \n",
            "Epoch 4300, Loss: 0.0002556479376525805, Nu:-4.74151523455287 \n",
            "Epoch 4400, Loss: 0.00025674920371650777, Nu:-4.73598424115677 \n",
            "Epoch 4500, Loss: 0.0002579110768454288, Nu:-4.7304419854761095 \n",
            "Epoch 4600, Loss: 0.0002596299859177271, Nu:-4.724890538891338 \n",
            "Epoch 4700, Loss: 0.00026034121952940554, Nu:-4.7193629510130135 \n",
            "Epoch 4800, Loss: 0.00026165088258639393, Nu:-4.713836766115902 \n",
            "Epoch 4900, Loss: 0.0002630017282671709, Nu:-4.708322645965405 \n",
            "Epoch 5000, Loss: 0.0002655133712229712, Nu:-4.702837858598814 \n",
            "Epoch 5100, Loss: 0.00026574638610413583, Nu:-4.697393073933493 \n",
            "Epoch 5200, Loss: 0.0002671925837214662, Nu:-4.691983959928772 \n",
            "Epoch 5300, Loss: 0.00026866500456661463, Nu:-4.68661621724217 \n",
            "Epoch 5400, Loss: 0.0002700776878751445, Nu:-4.681319618605656 \n",
            "Epoch 5500, Loss: 0.00027158461937562084, Nu:-4.676092213568134 \n",
            "Epoch 5600, Loss: 0.00027309989803502173, Nu:-4.670931900855385 \n",
            "Epoch 5700, Loss: 0.00027462479380064593, Nu:-4.665844024507844 \n",
            "Epoch 5800, Loss: 0.00027610489925387904, Nu:-4.66086533638378 \n",
            "Epoch 5900, Loss: 0.0002775850619247965, Nu:-4.655988479080792 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Truth',0.01)\n",
        "estimate_nu=np.exp(model.nu.item())\n",
        "print('Estimated alpha',estimate_nu)\n",
        "print('% error ', np.abs(  (estimate_nu-0.01)/0.01  )*100   )\n"
      ],
      "metadata": {
        "id": "L-LuGRvEQRvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0ef41cb-a09f-4b9d-c5a0-f2fa78d7857d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Truth 0.01\n",
            "Estimated alpha 0.009549591312279945\n",
            "% error  4.504086877200556\n"
          ]
        }
      ]
    }
  ]
}